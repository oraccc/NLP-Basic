## XLNet模型



### §10.1 XLNet模型简介

XLNet 是一个类似 BERT 的模型，而不是完全不同的模型。**XLNet是一种通用的自回归预训练方法**。它是CMU和Google Brain团队在2019年6月份发布的模型，最终，XLNet 在 20 个任务上超过了 BERT 的表现，并在 18 个任务上取得了当前最佳效果，包括机器问答、自然语言推断、情感分析和文档排序。

作者表示，BERT 这样基于**去噪自编码器**的预训练模型可以很好地建模双向语境信息，性能优于基于自回归语言模型的预训练方法。然而，由于需要 mask 一部分输入，BERT 忽略了被 mask 位置之间的依赖关系，因此出现预训练和微调效果的差异（pretrain-finetune discrepancy）。

基于这些优缺点，该研究提出了一种泛化的自回归预训练模型 XLNet。XLNet 可以：

- 通过最大化所有可能的因式分解顺序的对数似然，学习双向语境信息；
- 用自回归本身的特点克服 BERT 的缺点；
- 此外，XLNet 还**融合了当前最优自回归模型 Transformer-XL 的思路**。