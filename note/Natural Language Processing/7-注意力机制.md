## 注意力机制

- [注意力机制](#注意力机制)
  - [§7.1 注意力机制(Attention Mechanism)简介](#71-注意力机制attention-mechanism简介)
  - [§7.2 解编码器中的注意力机制](#72-解编码器中的注意力机制)
    - [计算背景变量](#计算背景变量)
      - [矢量化计算背景变量](#矢量化计算背景变量)
    - [更新隐藏状态](#更新隐藏状态)
  - [§7.3 进一步细解Attention本质](#73-进一步细解attention本质)
    - [从机器翻译说明Attention](#从机器翻译说明attention)
    - [注意力分配的方式](#注意力分配的方式)
    - [脱离Encoder-Decoder框架探讨Attention](#脱离encoder-decoder框架探讨attention)
      - [主流Attention函数](#主流attention函数)
      - [三阶段计算Attention过程](#三阶段计算attention过程)
  - [§7.4 Self-Attention](#74-self-attention)



### §7.1 注意力机制(Attention Mechanism)简介

> :memo: [Jupyter Notebook 代码](https://github.com/oraccc/NLP-Basic/blob/master/code/Natural%20Language%20Processing/7-attention.ipynb)

在 [编码器—解码器（seq2seq）](https://github.com/oraccc/NLP-Basic/blob/master/note/Natural%20Language%20Processing/6-Seq2Seq.md) ⼀节里，解码器在各个时间步依赖相同的背景变量来获取输入序列信息。当编码器为循环神经网络时，背景变量来自它最终时间步的隐藏状态。

现在，让我们再次思考上一节提到的翻译例子：

> 输入为英语序列`“They”,“are”,“watching”,“.”`，输出为法语序列`“Ils”,“regardent”,“.”`。
>
> 不难想到，解码器在生成输出序列中的每⼀个词时可能只需利用输入序列某⼀部分的信息。例如，在输出序列的时间步1，解码器可以主要依赖`“They”,“are”`的信息来生成`“Ils”`，在时间步2则主要使用来自`“watching”`的编码信息⽣成`“regardent”`，最后在时间步3则直接映射句号`“.”`。

这看上去就像是在解码器的每一时间步对输入序列中**不同时间步的表征或编码信息分配不同的注意力**⼀样。这也是注意力机制的由来。

仍然以循环神经网络为例，注意力机制通过对编码器所有时间步的隐藏状态**做加权平均来得到背景变量**。解码器在**每一时间步调整这些权重**，即注意力权重，从而能够在不同时间步分别关注输入序列中的不同部分并编码进相应时间步的背景变量。

在注意力机制中，解码器的每⼀时间步将使用**可变的背景变量**。记 $c_{t'}$ 是解码器在时间步 $t'$ 的背景变量，那么解码器在该时间步的隐藏状态可以改写为：
$$
s_{t'}=g(y_{t'-1}, c_{t'}, s_{t'-1})
$$
问题的关键是

* 如何计算背景变量 $c_{t'}$
* 如何用背景变量来更新隐藏状态 $s_{t'}$

---



### §7.2 解编码器中的注意力机制

#### 计算背景变量

下图描绘了注意力机制如何为**解码器**在**时间步 2** 计算背景变量

<img src="https://raw.githubusercontent.com/oraccc/NLP-Basic/master/img/attention/cal-background.png" width="550" />

* 函数 $a$ 根据**解码器在时间步 1 **的隐藏状态和**编码器在各个时间步**的隐藏状态计算softmax运算的输入
* softmax运算输出**概率分布**并对编码器各个时间步的隐藏状态做**加权平均**，从而得到背景变量

令编码器在时间步 $t$ 的隐藏状态为 $h_t$，且总时间步数为 $T$。那么解码器在时间步 $t′$ 的背景变量为所有编码器隐藏状态的加权平均：
$$
c_{t'} = \sum_{t=1}^T \alpha_{t't}h_{t}
$$

##### 矢量化计算背景变量

我们还可以对注意力机制采用更高效的矢量化计算。我们先定义，在上面的例子中，**查询项为解码器的隐藏状态**，**键项和值项均为编码器的隐藏状态**。

> 广义上，注意力机制的输入包括查询项以及⼀⼀对应的键项和值项，其中值项是需要加权平均的⼀组项。在加权平均中，值项的权重来自查询项以及与该值项对应的键项的计算。

让我们考虑⼀个常见的简单情形，即编码器和解码器的隐藏单元个数均为 $h$ ,并且函数 $a(s,h)=s^Th$

* 假设我们希望根据解码器单个隐藏状态 $s_{t'−1}$ 和编码器所有隐藏状态 $h_t, t = 1, . . . , T$ 来计算背景向量 $c_{t'}$ 
* 将查询矩阵 $Q$ 设为 $s_{t'-1}^{T}$, 并令键项矩阵 $K$ 和值项矩阵 $V$ 相同且第 $t$ 行均为 $h_t^T$
* 只需要矢量化计算 $softmax(QK^T)V$ 即可算出转置后的背景向量 $c_{t'}^T$

当查询项矩阵 $Q$ 的行数为 $n$ 时，上式将得到 $n$ 行的输出矩阵。输出矩阵与查询项矩阵在相同行上⼀⼀对应。



#### 更新隐藏状态

以门控循环单元（GRU）为例

对GRU的设计稍作修改，从而变换上⼀时间步 $t'−1$ 的输出 $y_{t'−1}$、隐藏状态 $s_{t'−1}$ 和当前时间步 $t'$ 的含注意力机制的背景变量 $c_{t'}$。

解码器在时间步 $t'$ 的隐藏状态为：
$$
s_{t'} = z_{t'} \odot s_{t'-1} + (1-z_{t'}) \odot \tilde{s}_{t'}
$$

其中的重置门、更新门和候选隐藏状态分别为
$$
r_{t'} = \sigma(W_{yr}y_{t'-1} + W_{sr}s_{t'-1} + W_{cr}c_{t'} + b_r) 
$$
$$
z_{t'} = \sigma(W_{yz}y_{t'-1} + W_{sz}s_{t'-1} + W_{cz}c_{t'} + b_z)
$$
$$
\tilde s_{t'} = tanh(W_{ys}y_{t'-1} + W_{ss}(s_{t'-1} \odot r_{t'}) + W_{cs}c_{t'} + b_s)
$$

---



### §7.3 进一步细解Attention本质

#### 从机器翻译说明Attention

首先以机器翻译作为例子讲解最常见的**Soft Attention模型**的基本原理，之后抛离Encoder-Decoder框架抽象出了注意力机制的本质思想。

> 如果拿机器翻译来解释这个Encoder-Decoder框架更好理解，比如输入的是英文句子：`Tom chase Jerry`，Encoder-Decoder框架逐步生成中文单词：`“汤姆”，“追逐”，“杰瑞”`。

在翻译`“杰瑞”`这个中文单词的时候，模型里面的每个英文单词对于翻译目标单词“杰瑞”贡献是相同的，很明显这里不太合理，**显然“Jerry”对于翻译成“杰瑞”更重要，但是模型是无法体现这一点的，这就是为何说它没有引入注意力的原因。**

没有引入注意力的模型在输入句子比较短的时候问题不大，但是如果输入句子比较长，此时**所有语义完全通过一个中间语义向量来表示，单词自身的信息已经消失**，可想而知会丢失很多细节信息，这也是为何要引入注意力模型的重要原因。

上面的例子中，如果引入Attention模型的话，应该在翻译`“杰瑞”`的时候，体现出英文单词对于翻译当前中文单词不同的影响程度，比如给出类似下面一个概率分布值：

`(Tom,0.3)(Chase,0.2)(Jerry,0.5)`

**每个英文单词的概率代表了翻译当前单词“杰瑞”时，注意力分配模型分配给不同英文单词的注意力大小**，这对于正确翻译目标语单词肯定是有帮助的，因为引入了新的信息。

同理，目标句子中的每个单词都应该学会其对应的源语句子中单词的注意力分配概率信息。这意味着在生成每个单词 $y_i$ 的时候，原先都是相同的中间语义表示 $C$ 会被替换成根据当前生成单词而不断变化的 $C_i$。理解Attention模型的关键就是这里，即由固定的中间语义表示 $C$ 换成了根据当前输出单词来调整成加入注意力模型的变化的 $C_i$。

增加了注意力模型的Encoder-Decoder框架理解起来如下图所示。

<img src="https://raw.githubusercontent.com/oraccc/NLP-Basic/master/img/attention/ed-with-attention.png" width="550" />

每个 $C_i$ 可能对应着不同的源语句子单词的注意力分配概率分布，比如对于上面的英汉翻译来说，其对应的信息可能如下
$$
C_{汤姆} = g(0.6 * f_2(Tom), 0.2 * f_2(chase), 0.2 * f_2(Jerry))
$$
$$
C_{追逐} = g(0.2 * f_2(Tom), 0.7 * f_2(chase), 0.1 * f_2(Jerry))
$$
$$
C_{杰瑞} = g(0.3 * f_2(Tom), 0.2 * f_2(chase), 0.5 * f_2(Jerry))
$$
其中，$f_2$ 函数代表Encoder对输入英文单词的某种变换函数，比如Encoder是用的RNN模型的话，这个 $f_2$ 函数的结果往往是某个时刻输入 $x_i$ 后隐层节点的状态值；

$g$ 代表Encoder根据单词的中间表示合成整个句子中间语义表示的变换函数，一般的做法中，$g$ 函数就是对构成元素加权求和，即下列公式：
$$
C_i = \sum _{j=1}^{L_x} a_{ij}h_{j}
$$
其中，$L_x$ 代表输入句子Source的长度，$a_{ij}$ 代表在Target输出第 $i$ 个单词时Source输入句子中第 $j$ 个单词的注意力分配系数，而 $h_j$ 则是Source输入句子中第 $j$ 个单词的语义编码。

> 假设下标i就是上面例子所说的`“汤姆”` ，那么 $L_x$ 就是3，$h_1=f(Tom), h_2=f(chase), h_3=f(Jerry)$ 分别是输入句子每个单词的语义编码，对应的注意力模型权值则分别是`0.6, 0.2, 0.2`，所以 $g$ 函数本质上就是个**加权求和函数**。 

<img src="https://raw.githubusercontent.com/oraccc/NLP-Basic/master/img/attention/cal-Ci.png" width="300" />

#### 注意力分配的方式

上面的注意力 $(a_{11}、a_{12}、a_{13})$ 是我们人工分配的，那模型中注意力是怎么计算的呢？

这就需要用到**对齐模型**，来衡量encoder端的位置 $j$ 的词，对于decoder端的位置 $i$ 个词的对齐程度（影响程度），换句话说：decoder端生成位置 $i$ 的词时，有多少程度受encoder端的位置 $j$ 的词影响。对齐模型的计算方式有很多种，不同的计算方式，代表不同的Attention模型，最简单且最常用的的对齐模型是**dot product乘积矩阵**，即把target端的输出隐状态 $h_t$ 与source端的输出隐状态 $h_s$ 进行矩阵乘。

下面是常见的对齐计算方式：

$$
score(h_t, \bar {h}_s)=\begin{cases}
h_{t}^{\top} \bar {h}_s & dot \\
h_{t}^{\top} W_{\alpha} \bar {h}_s & general \\
v_{\alpha}^{\top} tanh(W_{\alpha}[h_t;\bar {h}_s]) & concat
\end{cases}
$$

其中, $score(h_t,\bar {h} _s) = a_{ij}$ 表示源端与目标单单词对齐程度。常见的对齐关系计算方式有：点乘（Dot product），权值网络映射（General）和Concat映射几种方式。

<img src="https://raw.githubusercontent.com/oraccc/NLP-Basic/master/img/attention/cal-coeff.png" width="500" />

对于采用RNN的Decoder来说，在时刻 $i$，如果要生成 $y_i$ 单词，我们是可以知道Target在生成 $y_i$ 之前的时刻 $i-1$ 时，隐层节点 $i-1$ 时刻的输出值 $H_{i-1}$ 的，而我们的目的是要计算生成 $y_i$ 时输入句子中的单词`“Tom”、“Chase”、“Jerry”`对 $y_i$ 来说的注意力分配概率分布，那么可以用Target输出句子 $i-1$ 时刻的隐层节点状态 $H_{i-1}$ 去**一一和输入句子Source中每个单词对应的RNN隐层节点状态 $h_j$ 进行对比**，即通过函数 $F(h_j,H_{i-1})$ 来获得目标单词 $y_i$ 和每个输入单词对应的对齐可能性，这个 $F$ 函数在不同论文里可能会采取不同的方法，然后函数 $F$ 的输出经过Softmax进行归一化就得到了**符合概率分布取值区间的注意力分配概率分布数值**。



> 流程总结：**Encoder-Decoder架构下的 Attention** 计算动图如下

<img src="https://raw.githubusercontent.com/oraccc/NLP-Basic/master/img/attention/attention.gif" width="500" />



#### 脱离Encoder-Decoder框架探讨Attention

Attention机制其实就是一系列**注意力分配系数**

##### 主流Attention函数

<img src="https://raw.githubusercontent.com/oraccc/NLP-Basic/master/img/attention/attention-structure.png" width="500" />

我们将Source中的元素想像成一系列的**<Key,Value>**数据对，此时指定Target中的某个元素**Query**，通过计算Query和各个元素相似性或者相关性，得到每个Key对应Value的权重系数，然后对Value进行加权求和，得到最终的Attention值。
$$
Attention(Query, Source) = \sum_{i=1}^{L_x}Similarity(Query, Key_i)*Value_i
$$
其中，$L_x=||Source||$ 代表Source的长度

**本质上Attention机制是对Source中元素的Value值进行加权求和，而Query和Key用来计算对应Value的权重系数。**

> 可以将Attention机制看做**软寻址**，序列中每一个元素都由key(地址)和value(元素)数据对存储在存储器里，当有query=key的查询时，需要取出元素的value值(也**即query查询的attention值**)，与传统的寻址不一样，它不是按照地址取出值的，它是通过计算key与query的相似度来完成寻址。
>
> 这就是所谓的软寻址，它可能会把所有地址(key)的值(value)取出来，上步计算出的相似度决定了取出来值的重要程度，然后按重要程度合并value值得到attention值，此处的合并指的是加权求和。

##### 三阶段计算Attention过程

基于上面的推广，Attention函数共有三步完成得到Attention值。

- 阶段1:Query与Key进行相似度计算得到权值
- 阶段2:对上一阶段的计算的权重进行归一化
- 阶段3:用归一化的权重与Value加权求和，得到Attention值

<img src="https://raw.githubusercontent.com/oraccc/NLP-Basic/master/img/attention/3step-attention.png" width="500" />

---



### §7.4 Self-Attention

**Self Attention**也经常被称为Intra Attention（内部Attention），最近一年也获得了比较广泛的使用，比如Google最新的机器翻译模型内部大量采用了Self Attention模型。

* 在一般任务的Encoder-Decoder框架中，输入Source和输出Target内容是不一样的，比如对于英-中机器翻译来说，Source是英文句子，Target是对应的翻译出的中文句子，Attention机制发生在Target的元素Query和Source中的所有元素之间。

* **而Self Attention顾名思义，指的不是Target和Source之间的Attention机制，而是Source内部元素之间或者Target内部元素之间发生的Attention机制，也可以理解为Target=Source这种特殊情况下的注意力计算机制。**其具体计算过程是一样的，只是计算对象发生了变化而已，所以此处不再赘述其计算过程细节。

很明显，引入Self Attention后**会更容易捕获句子中长距离的相互依赖的特征**，因为如果是RNN或者LSTM，需要依次序序列计算，对于远距离的相互依赖的特征，要经过若干时间步步骤的信息累积才能将两者联系起来，而距离越远，有效捕获的可能性越小。

但是Self Attention在计算过程中会直接将句子中任意两个单词的联系通过一个计算步骤直接联系起来，所以远距离依赖特征之间的距离被极大缩短，有利于有效地利用这些特征。除此外，Self Attention对于增加计算的并行性也有直接帮助作用。这是为何Self Attention逐渐被广泛使用的主要原因。

---

