## NLP 概述

- [NLP 概述](#nlp-概述)
  - [§0.1 总体概述](#01-总体概述)
    - [:one:什么是NLP？](#one什么是nlp)
    - [:two:NLP的主要研究方向?](#twonlp的主要研究方向)
    - [:three:NLP的发展](#threenlp的发展)
  - [§0.2 NLP任务的基本步骤](#02-nlp任务的基本步骤)
    - [:one:获取语料](#one获取语料)
    - [:two:语料预处理](#two语料预处理)
    - [:three:特征工程](#three特征工程)
    - [:four:特征选择](#four特征选择)
    - [:five:模型训练](#five模型训练)
    - [:six:评价指标](#six评价指标)
    - [:seven:模型上线应用](#seven模型上线应用)

### §0.1 总体概述

#### :one:什么是NLP？

* 自然语言处理 (**N**atural **L**anguage **P**rocessing) 是人工智能的一个子领域。
* 自然语言处理是研究在人与人交互中以及在人与计算机交互中的**语言问题**的一门学科

#### :two:NLP的主要研究方向?

- **信息提取**：从给定文本中抽取重要的信息，比如时间、地点、人物、事件、原因、结果、数字、日期、货币、专有名词等等
- **文本生成**：机器像人一样使用自然语言进行表达和写作。依据输入的不同，文本生成技术主要包括<u>数据到文本生成</u>和<u>文本到文本生成</u>。
  - 数据到文本生成是指将包含键值对的数据转化为自然语言文本
  - 文本到文本生成对输入文本进行转化和处理从而产生新的文本
- **问答、对话系统**
  - **问答**：对一个自然语言表达的问题，由问答系统给出一个精准的答案。需要对自然语言查询语句进行某种程度的语义分析，包括<u>实体链接、关系识别，形成逻辑表达式</u>，然后到知识库中查找可能的候选答案并通过一个排序机制找出最佳的答案
  - **对话**：系统通过一系列的对话，跟用户进行聊天、回答、完成某一项任务。涉及到用户意图理解、通用聊天引擎、问答引擎、对话管理等技术。此外，为了体现上下文相关，要具备多轮对话能力
- **文本挖掘**：包括文本聚类、分类、情感分析以及对挖掘的信息和知识的可视化、交互式的表达界面
- **语音识别和生成**：
  - 语音识别是将输入计算机的语音符号识别转换成书面语表示
  - 语音生成又称文语转换、语音合成，它是指将书面文本自动转换成对应的语音表征
- **信息过滤**: 通过计算机系统自动识别和过滤符合特定条件的文档信息。通常指网络有害信息的自动识别和过滤，主要用于信息安全和防护，网络内容管理等
- **舆情分析**: 是指收集和处理海量信息，自动化地对网络舆情进行分析，以实现及时应对网络舆情的目的
- **信息检索**
  - 对大规模的文档进行索引。可简单对文档中的词汇，赋之以不同的权重来建立索引，也可建立更加深层的索引。
  - 在查询的时候，对输入的查询表达式比如一个检索词或者一个句子进行分析，然后在索引里面查找匹配的候选文档，再根据一个排序机制把候选文档排序，最后输出排序得分最高的文档
- **机器翻译**: 把输入的源语言文本通过自动翻译获得另外一种语言的文本。机器翻译从最早的基于规则的方法到二十年前的基于统计的方法，再到今天的基于神经网络（<u>编码-解码</u>）的方法，逐渐形成了一套比较严谨的方法体系

#### :three:NLP的发展

- 基于规则形式语言理论
- 基于统计
- 基于机器学习

---

### §0.2 NLP任务的基本步骤

#### :one:获取语料

* 语料：NLP所研究的内容
* 语料库（Corpus）：文本的集合

#### :two:语料预处理

* 语料清洗
  * 人工去重、对齐、删除和标注
* 分词
  * 基于字符串匹配的分词方式
  * 基于理解的分词方式
  * 基于统计的分词方式
  * 基于规则的分词方式
* 词性标注
  * 常用于**情感分析**、**知识推理**（知识推理任务是从给定的段落和问题中找到相应答案的任务）任务
  * 词性标注的方法
    * 基于统计（最大概率输出词性、基于[HMM(Hidden Markov Models)](https://blog.csdn.net/u013166817/article/details/85805513)的词性标注）
    * 基于规则
* 去停用词
  * 标点、语气助词、人称

#### :three:特征工程

* 将分词表示成计算机可以理解的向量形式
* 常见的表示模型
  * **词袋模型**（BOW)，**TF-IDF**
  * **词向量** 
    * One-hot
    * Word2Vec

#### :four:特征选择

* 选择合适的、表达能力强的特征
  * DF(Document Frequency): 统计特征词出现的文档数量，用来衡量某个特征词的重要性。越高越重要
  * MI(Mutual Information): 互信息法用于衡量特征词与文档类别直接的信息量。如果某个特征词的频率很低，那么互信息得分就会很大，因此互信息法倾向"低频"的特征词。
  * IG(Information Gain): 通过某个特征词的缺失与存在的两种情况下，语料中前后信息的增加，衡量某个特征词的重要性
  * CHI(Chi-square): 利用了统计学中的"假设检验"的基本思想: 首先假设特征词与类别直接是不相关的，如果利用CHI分布计算出的检验值偏离阈值越大，那么更有信心否定原假设，接受原假设的备择假设：特征词与类别有着很高的关联度。
  * WLLR(Weighted Log Likelihood Ration)
  * WFO(Weighted Frequency and Odds)

#### :five:模型训练

* 模型的分类
  * 机器学习：KNN、SVM、Naive Bayes、Decision Tree、GBDT(Gradient Boosting Decision Tree)、K-means
  * 深度学习: CNN、RNN、LSTM、Seq2Seq、FastText、TextCNN
* 过拟合和欠拟合问题
  * 过拟合：在训练集上表现好，在测试集上表现差
    * 增大数据的训练量、正则化、重新进行特征选取、Dropout方法
  * 欠拟合、模型不能很好地拟合数据
    * 添加特征项、增加模型的复杂度（更多层、增加模型的泛化能力）、减少正则化参数
  * 梯度消失和梯度爆炸问题

#### :six:评价指标

* Accuracy, Precision, Recall, F1
* [ROC](https://blog.csdn.net/qq_40728667/article/details/123119335)(Receiver Operating Characteristic) ,AUC(Area under Curve)

#### :seven:模型上线应用

---